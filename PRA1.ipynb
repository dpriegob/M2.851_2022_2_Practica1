{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6924ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = r'C:\\Program Files\\Mozilla Firefox\\firefox.exe'\n",
    "driver = webdriver.Firefox(executable_path=r'C:\\Users\\dpriego\\Anaconda3\\geckodriver.exe', options=options)\n",
    "\n",
    "wait_sec = 20\n",
    "url_income_statement = 'https://finance.yahoo.com'\n",
    "driver.get(url_income_statement)\n",
    "driver.maximize_window()\n",
    "\n",
    "#Obtener user agent\n",
    "user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "print(\"User agent:\", user_agent)\n",
    "\n",
    "#Click boton aceptar coockies\n",
    "element = driver.find_element_by_xpath(\"/html/body/div/div/div/div/form/div[2]/div[2]/button[1]\")\n",
    "driver.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "#Click boton Industries\n",
    "driver.implicitly_wait(wait_sec)\n",
    "driver.find_element_by_xpath(\"//a[@title='Industries']\").click()\n",
    "\n",
    "#Click boton acciones de empresas tecnológicas\n",
    "driver.implicitly_wait(wait_sec)\n",
    "driver.find_element_by_xpath(\"//a[@title='Technology']\").click()\n",
    "\n",
    "#Obtenemos el listado de las distintas compañías\n",
    "driver.implicitly_wait(wait_sec)\n",
    "html_tech_sheet = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "element = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/section/div/div[2]/div[2]/button[3]\")\n",
    "rows = []\n",
    "header = []\n",
    "salir = False\n",
    "table = html_tech_sheet.find('table')\n",
    "while not salir:  \n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i == 0:\n",
    "            header = [el.text.strip() for el in row.find_all('th')]\n",
    "        else:\n",
    "            rows.append([el.text.strip() for el in row.find_all('td')])\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/section/div/div[2]/div[2]/button[3]\")    \n",
    "    if not element.is_enabled():\n",
    "        salir = True\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/section/div/div[2]/div[2]/button[3]\").click()\n",
    "    html_tech_sheet = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = html_tech_sheet.find('table')\n",
    "\n",
    "#Extraemos el identificador y nombre de cada empresa en un diccionaro para realizar el scraping de cada una de ellas:\n",
    "companys = {}\n",
    "for c in rows:\n",
    "    if c[0] not in companys.keys():\n",
    "        companys[c[0]] = c[1]\n",
    "firstLoop = True\n",
    "regexDate = re.compile('[@_!#?/\\|}{~:]')\n",
    "headers = [\"Company\", \"Period\", \"Concept\", \"Value\"]\n",
    "df = pd.DataFrame(columns=headers)\n",
    "values = []\n",
    "i = 0\n",
    "#for key, value in companys.items():\n",
    "#Recorremos las empresas y obtenemos la información financiera:\n",
    "for key in list(companys.keys())[0:3]:\n",
    "    periodo = [\"TTM\"]\n",
    "    ticker = key\n",
    "    url_income_statement = 'https://finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
    "    driver.get(url_income_statement)\n",
    "    \n",
    "    #Click boton registrarse luego\n",
    "    if firstLoop:      \n",
    "        WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "        \"/html/body/div[1]/div/div/div[1]/div/div[4]/div/div/div[1]/div/div/div/div/div/section/button[2]\"))).click()\n",
    "        firstLoop = False\n",
    "\n",
    "    #Click boton Expandir datos\n",
    "    WebDriverWait(driver, 5)\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "    \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/div/div/section/div[2]/button/div/span\"))).click()\n",
    "    \n",
    "    html_income_statement = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    #Navegamos a balance-sheet\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "    \"a[href*='balance-sheet']\"))).click()\n",
    "\n",
    "    #Click boton Expandir datos\n",
    "    WebDriverWait(driver, 5)\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "    \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/section/div[2]/button/div/span\"))).click()\n",
    "    \n",
    "    html_balance_sheet = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #Navegamos a cash-flow\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "    \"a[href*='cash-flow']\"))).click()\n",
    "    \n",
    "    #Click boton Expandir datos\n",
    "    WebDriverWait(driver, 5)\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "    \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/section/div[2]/button/div/span\"))).click()\n",
    "\n",
    "    WebDriverWait(driver, 5)\n",
    "    html_cash_flow = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #Obtenemos los datos de la tabla income_statement, los pasamos a un dataframe y finalmente los guardamos en un fichero\n",
    "    income_statement = html_income_statement.findAll('span', attrs={\"data-test\":\"\"})\n",
    "    start_scraping = False\n",
    "    values = []\n",
    "    for index, val in enumerate(income_statement):\n",
    "        if (val.text == \"ttm\"): start_scraping = True\n",
    "        if (val.text == \"People Also Watch\"): start_scraping = False\n",
    "        if (start_scraping == True): \n",
    "            if (regexDate.search(val.text) != None):\n",
    "                    periodo.append(val.text)  \n",
    "            elif (val.text.find(\",\")) > 0 or val.text==\"0\":\n",
    "                values.append(val.text)            \n",
    "                while len(values) != len(df.columns):\n",
    "                       values.append(0) \n",
    "                df.loc[len(df)] = values\n",
    "                df.loc[df.shape[0]-1,\"Period\"] = periodo[i]\n",
    "                i+=1\n",
    "                values.pop()\n",
    "            else:    \n",
    "                values = []\n",
    "                i = 0\n",
    "                values.insert(0,companys[key])  \n",
    "                values.insert(1,\"\")\n",
    "                values.append(val.text)\n",
    "df.to_excel('FinanceData.xlsx', index=False)          \n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
