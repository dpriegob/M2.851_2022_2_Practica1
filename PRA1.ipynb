{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ce8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = r'C:\\Program Files\\Mozilla Firefox\\firefox.exe'\n",
    "driver = webdriver.Firefox(executable_path=r'C:\\Users\\dpriego\\Anaconda3\\geckodriver.exe', options=options)\n",
    "\n",
    "wait_sec = 20\n",
    "url_income_statement = 'https://finance.yahoo.com'\n",
    "driver.get(url_income_statement)\n",
    "driver.maximize_window()\n",
    "\n",
    "#Click boton aceptar coockies\n",
    "element = driver.find_element_by_xpath(\"/html/body/div/div/div/div/form/div[2]/div[2]/button[1]\")\n",
    "driver.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "#Click boton Industries\n",
    "driver.implicitly_wait(wait_sec)\n",
    "driver.find_element_by_xpath(\"//a[@title='Industries']\").click()\n",
    "\n",
    "#Click boton acciones de empresas tecnológicas\n",
    "driver.implicitly_wait(wait_sec)\n",
    "driver.find_element_by_xpath(\"//a[@title='Technology']\").click()\n",
    "\n",
    "#Obtenemos el listado de los id's de las distintas compañías\n",
    "driver.implicitly_wait(wait_sec)\n",
    "html_tech_sheet = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "element = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/section/div/div[2]/div[2]/button[3]\")\n",
    "rows = []\n",
    "header = []\n",
    "salir = False\n",
    "table = html_tech_sheet.find('table')\n",
    "while not salir:  \n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i == 0:\n",
    "            header = [el.text.strip() for el in row.find_all('th')]\n",
    "        else:\n",
    "            rows.append([el.text.strip() for el in row.find_all('td')])\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/section/div/div[2]/div[2]/button[3]\")    \n",
    "    if not element.is_enabled():\n",
    "        salir = True\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/section/div/div[2]/div[2]/button[3]\").click()\n",
    "    html_tech_sheet = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = html_tech_sheet.find('table')\n",
    "#Extraemos el identificador de cada empresa para poder realizar el scraping de cada una de ella:\n",
    "idComapanys = []\n",
    "for c in rows:\n",
    "    if c not in idComapanys:\n",
    "        idComapanys.append(c[0])\n",
    "firstLoop = True\n",
    "regexDate = re.compile('[@_!#?/\\|}{~:]')\n",
    "headers = [\"Company\", \"Breakdown\", \"ttm\"]\n",
    "df = pd.DataFrame(columns=headers)\n",
    "for el in range(3):\n",
    "    ticker = idComapanys[el]\n",
    "    url_income_statement = 'https://finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
    "    driver.get(url_income_statement)\n",
    "    \n",
    "    #Click boton registrarse luego\n",
    "    if firstLoop:      \n",
    "        WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "        \"/html/body/div[1]/div/div/div[1]/div/div[4]/div/div/div[1]/div/div/div/div/div/section/button[2]\"))).click()\n",
    "        firstLoop = False\n",
    "\n",
    "    #Click boton Expandir datos\n",
    "    WebDriverWait(driver, 5)\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "    \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/div/div/section/div[2]/button/div/span\"))).click()\n",
    "    \n",
    "    html_income_statement = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    #Navegamos a balance-sheet\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "    \"a[href*='balance-sheet']\"))).click()\n",
    "\n",
    "    #Click boton Expandir datos\n",
    "    WebDriverWait(driver, 5)\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "    \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/section/div[2]/button/div/span\"))).click()\n",
    "    \n",
    "    html_balance_sheet = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #Navegamos a cash-flow\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "    \"a[href*='cash-flow']\"))).click()\n",
    "    \n",
    "    #Click boton Expandir datos\n",
    "    WebDriverWait(driver, 5)\n",
    "    WebDriverWait(driver, wait_sec).until(EC.element_to_be_clickable((By.XPATH,\n",
    "    \"/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/section/div[2]/button/div/span\"))).click()\n",
    "\n",
    "    WebDriverWait(driver, 5)\n",
    "    html_cash_flow = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #Datos income_statement\n",
    "    income_statement = html_income_statement.findAll('span', attrs={\"data-test\":\"\"})\n",
    "    start_scraping = False\n",
    "    values = []\n",
    "    for index, val in enumerate(income_statement):\n",
    "        if (val.text == \"Breakdown\"): start_scraping = True\n",
    "        if (val.text == \"People Also Watch\"): start_scraping = False\n",
    "        if (start_scraping == True): \n",
    "            if (regexDate.search(val.text) != None):\n",
    "                chunks = val.text.split('/')\n",
    "                if chunks[2] not in headers:\n",
    "                    df[chunks[2]] = np.nan\n",
    "                    headers.append(chunks[2])\n",
    "            elif (val.text.find(\",\")) > 0:\n",
    "                values.append(val.text)\n",
    "            else:    \n",
    "                if val.text not in df.columns:\n",
    "                    if len(values) > 2:\n",
    "                        if len(values) == len(df.columns): \n",
    "                            df.loc[len(df)] = values\n",
    "                    values = []               \n",
    "                    values.insert(0,ticker)\n",
    "                    values.append(val.text)   \n",
    "          \n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
